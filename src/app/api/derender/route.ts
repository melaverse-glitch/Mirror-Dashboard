import { GoogleGenerativeAI } from "@google/generative-ai";
import { NextResponse } from "next/server";

export async function POST(req: Request) {
    try {
        const { image, mimeType } = await req.json();

        if (!image) {
            return NextResponse.json(
                { error: "Image data is required" },
                { status: 400 }
            );
        }

        const apiKey = process.env.GOOGLE_API_KEY;
        if (!apiKey) {
            return NextResponse.json(
                { error: "GOOGLE_API_KEY is not set" },
                { status: 500 }
            );
        }

        const genAI = new GoogleGenerativeAI(apiKey);

        // Using the specific model requested: gemini-3-pro-image-preview
        // Note: If this model ID is not available, we might need fallback logic or user confirmation
        const model = genAI.getGenerativeModel({
            model: "gemini-3-pro-image-preview",
            systemInstruction: "You are a professional cosmetic skin analyst. Your task is to 'derender' the provided portrait. 1. Analyze the skin tone in areas with minimal makeup (like the neck or hairline). 2. Remove all visible makeup (foundation, eye shadow, lipstick, blush, mascara). 3. DO NOT change the user's facial structure, bone structure, or eye shape. 4. Preserve natural skin textures, freckles, or moles. 5. Output a high-fidelity 'natural' version of the person."
        });

        const prompt = "Derender this image. Remove all makeup showing the natural skin underneath. Maintain high photorealism.";

        // Construct the image part
        const imagePart = {
            inlineData: {
                data: image,
                mimeType: mimeType || "image/jpeg",
            },
        };

        // The instruction implies an Image-to-Image capability where the output is an image.
        // Standard Gemini models (pro-vision) output text, but 'image-preview' or specialized experimental models might output an image 
        // or we might need to be using a different endpoint if this is a generated image model (like Imagen).
        // However, based on the specific "gemini-3-pro-image-preview" name, it sounds like an experimental multimodal-to-multimodal model.
        // We will assume standard generateContent flow but look for image in payload if it comes back as such, 
        // OR if it returns a path/url/base64 in the text.

        // CRITICAL ASSUMPTION CHECK:
        // If the model generates an image, the SDK response format might be different. 
        // For now, we will try `model.generateContent`.

        const result = await model.generateContent([prompt, imagePart]);
        const response = await result.response;

        // Logic to handle Image Output if supported natively by SDK for this model
        // Usually, image generation models return an 'images' array or similar.
        // If this is a text-model describing the change, this will fail the user expectation. 
        // But since the user INSISTED on this model and "Image-to-Image", we assume functionality.

        // Note for User: Currently the standard Node SDK `generateContent` returns text parts. 
        // If the model returns regular image bytes, they might be in `candidates[0].content.parts[0].inlineData` or similar if the SDK supports reception.
        // If not, we might need to parse. 

        // Let's assume standard response handling first, but if this was 'imagen', we'd use a different method.
        // Since I cannot know the exact shape of this unreleased/experimental model's response without docs,
        // I will look for any "inlineData" in the parts.

        const parts = response.candidates?.[0]?.content?.parts;
        const imageOutput = parts?.find(p => p.inlineData)?.inlineData;

        if (imageOutput) {
            return NextResponse.json({
                image: imageOutput.data,
                mimeType: imageOutput.mimeType
            });
        }

        // Fallback: Check if it returned a text that IS a base64 string or URL (unlikely but possible)
        const textOutput = response.text();
        if (textOutput) {
            // If the model refused or returned text, we pass it back (or error out if it needs to be an image)
            // For this specific 'derender' task, text is useless.
            console.log("Model returned text instead of image:", textOutput);
            // We'll return it for debugging, but the UI expects an image.
            // In a real scenario, this is where we'd likely hit an error if the model isn't set up for straight image-out.
        }

        return NextResponse.json({ error: "No image generated by model", rawText: textOutput });

    } catch (error) {
        console.error("API Error:", error);
        return NextResponse.json(
            { error: "Internal Server Error", details: error instanceof Error ? error.message : String(error) },
            { status: 500 }
        );
    }
}
